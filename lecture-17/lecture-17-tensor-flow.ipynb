{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "\n",
    "TensorFlow is an extensive machine learning library built by Google, it is specialized for deep learning.\n",
    "\n",
    "One of the advantages of TensorFlow is that it supports building end-to-end solutions. TensorFlow provides a variety of machine learning algorithms and models that can be used easily, and manages the execution of these algorithms during data preparation, training, evaluation, and deployment.\n",
    "\n",
    "In particular, TensorFlow is compatible with a variety of CPU and GPU architectures, and can effectively manage clusters of computing resources, for purposes of replication and data-parallelization.\n",
    "\n",
    "Additionally, TensorFlow provides compatible libraries for the web (Node.js and Browser), and mobile and IoT devices. It also has a large toolkit associated with it, that help developers visualize and validate their implmenetations. We will use one of these tools in this note, which visualizes TensorFlow graphs nicely.\n",
    "\n",
    "Below we import the needed extensions to Jupyter Notebook, and use the appropriate magic functions, so that Jupyter can use the visualization tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "def visualize(graph, name):\n",
    "    from tensorflow.python.summary.writer.writer import FileWriter\n",
    "    FileWriter('logs/'+name, graph=graph).close()\n",
    "    %tensorboard --logdir logs/$name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Versions\n",
    "\n",
    "TensorFlow has two main versions: v1, and v2. There are large differences between the two versions, from the perspective of users. V2 has a lot of improvements that make its API friendlier, and make it more efficient. However, both versions share a lot of design ideas behind the scenes.\n",
    "\n",
    "We will begin by looking at v1 briefly, and then contrast it with some of the new features in v2, to help us understand how TensorFlow operate from the perspective of framework design and embedding.\n",
    "\n",
    "We begin by importing a v1 compatible version of TensorFlow, and disabling eager execution (more on this later). This ensures that the semantics of TensorFlow is very close to v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tf with a v1 compatible API\n",
    "import tensorflow.compat.v1 as tf \n",
    "\n",
    "# disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# in reality, we are still using v2\n",
    "# but we will have the illusion of using v1\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow V1: Manual Graph Definition\n",
    "\n",
    "In V1, TensorFlow has two important concepts: **Graph** and **Session**.\n",
    "\n",
    "A Graph is similar to a blueprint. It consists of a *flow* of instructions. TensorFlow can support having several graphs, each built seperately. Additionally, TensorFlow always has a default graph initialized, so that applications with a single graph does not need to manually intialize one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have two different graphs now: False\n",
      "Both graphs are empty: [] []\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "g2 = tf.get_default_graph()\n",
    "\n",
    "print('We have two different graphs now:', g1 is g2)\n",
    "print('Both graphs are empty:', g1.get_operations(), g2.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can be assigned instructions in some order using tensorflow's API.\n",
    "\n",
    "Graphs Do not contain real data in them. Instead, they are made out of symbolic handlers and symbolic operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our graph is now the default graph: True\n",
      "\n",
      "a, b = Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_1:0\", shape=(), dtype=float32)\n",
      "\n",
      "The graph: <tensorflow.python.framework.ops.Graph object at 0x7f27532e4588>\n",
      "Const\n",
      "Const_1\n",
      "Add\n",
      "add_1\n",
      "\n",
      " True []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    print('Our graph is now the default graph:', g1 is tf.get_default_graph())\n",
    "    print('')\n",
    "\n",
    "    a = tf.constant(1.0)\n",
    "    b = tf.constant(2.0)\n",
    "    # constants do not expose their values during graph construction\n",
    "    print('a, b =', a, b)\n",
    "\n",
    "    c = tf.add(a, b) # very verbose\n",
    "    c = a + b # fortunetly, TensorFlow uses operator overloading\n",
    "    print(c) # + is not executed during construction\n",
    "\n",
    "    print('\\nThe graph:', g1)\n",
    "    for op in g1.get_operations():\n",
    "        print(op.name)\n",
    "\n",
    "# the default graph has been reset, and it is still empty\n",
    "print('\\n', g2 is tf.get_default_graph(), g2.get_operations())\n",
    "print(g2.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use tensorflow tools and the Jupyter notebook extension to visualize our graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(g1, 'g1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- for exporting to HTML\n",
    "![turned into static image due to exporting to HTML](static/images/tensorflow-graph1.png)\n",
    "-->\n",
    "\n",
    "After a graph is built, it can be run within a session. At that moment, the graph is instantiated with concrete values, and the operations are really run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 3.0\n",
      "a, b = 1.0 2.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as session:\n",
    "    print('result:', session.run(c))\n",
    "    print('a, b =', session.run(a), session.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many ways, a graph is just a program, while a session is the act of running that program.\n",
    "\n",
    "We can define more complicated graphs, that include loops, conditionals, and variables. All using TensorFlow's API. Additionlly, graph and session definition can be mixed together if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    with tf.Session(graph=g) as session:\n",
    "        t = tf.Variable(5.0, name='var')\n",
    "        session.run(t.initializer)\n",
    "    \n",
    "        c = tf.constant(0.0)\n",
    "        p = tf.placeholder('float')\n",
    "    \n",
    "        # this can be annoying when having several nested conditions or loops\n",
    "        # body of every construct has to be a function or lambda\n",
    "        t = tf.cond(t < p, lambda: t.assign(10), lambda: t.assign(0))\n",
    "        result = tf.cond(tf.equal(t, c), lambda: tf.constant(1), lambda: tf.constant(0))\n",
    "\n",
    "        print(session.run(result, {p: 8}))\n",
    "        print(session.run(result, {p: 8}))\n",
    "        print(session.run(result, {p: -1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to pay attention to is expressing the dependencies between operations. TensorFlow only runs the operations it thinks are required to produce the desired result, but not other operations. TensorFlow tracks these dependencies by tracking variable usage in the graph definition. Here is a demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    with tf.Session(graph=g) as session:\n",
    "        t = tf.Variable(10.0, name='var')\n",
    "        session.run(t.initializer)\n",
    "    \n",
    "        # so far, t has no operations associated to it\n",
    "        print(session.run(t))\n",
    "\n",
    "        # surprinsingly, this shows 10, this is because the assignment\n",
    "        # operation was not executed! TensorFlow did not realize that it\n",
    "        # is relevant\n",
    "        t.assign(1)\n",
    "        print(session.run(t))\n",
    "\n",
    "        # now this works, since we are asking TensorFlow to run t AFTER\n",
    "        # the assignment\n",
    "        t = t.assign(1)\n",
    "        print(session.run(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the resulting graph as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(g, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- for exporting to HTML\n",
    "![turned into static image due to exporting to HTML](static/images/tensorflow-graph2.png)\n",
    "-->\n",
    "\n",
    "### Design Rationale\n",
    "\n",
    "This seems complicated at first glance, why write a python program, that builds a graph (i.e. a tensorflow custom program), and then run it inside a session? Why not execute Tensorflow directly via python constructs? Indeed, TensorFlow v2 supports this more straightforward embedding.\n",
    "\n",
    "However, the reason TensorFlow started out with this abstract and convoluted design is important, and very relevant to things we have already seen in class: Assume the additional layer of a graph was not used, and the program ran directly in Python. It will be very difficult for TensorFlow to have complete information about the entire program. Instead, it can only obserave the state of the program as it executed dynamically. This means that TensorFlow cannot know for sure what future instructions will be executed (since they have not been reached yet!), and cannot for sure know that running the program again will result in the same set of instructions (because of dynamic branching and looping).\n",
    "\n",
    "TensorFlow requires this global picture of the program (or at least portions of it), since it is essential to being able to manage and distribute the operations of the program correctly and efficiently.\n",
    "\n",
    "Therefore, TensorFlow had two options to get this global picture:\n",
    "1. Implement some static code analyzer that can parse the user code and understand its structure.\n",
    "2. Force users to specify their programs symbolically using TensorFlow's API.\n",
    "\n",
    "As we have seen in our class, the first option can be very challenging to build accurately, and may run into undecidablities in the general case. It is burdensome to specify exactly which restrictions are imposed on user code to make analyzing it statically feasible for this application domain. Furthermore, it is difficult to communicate these restrictions effectively to the programmers, or enforce them by the static analyzer. This explains why TensorFlow chose the second approache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow V2: Simplified Abstraction\n",
    "\n",
    "TensorFlow v2 simplifies the programming abstraction, while keeping a lot of the performance benefits.\n",
    "\n",
    "It re-designs how graphs are created, and how sessions are managed and run.\n",
    "\n",
    "In particular, a TensorFlow computation using v2 can be defined in two ways:\n",
    "1. **Eager Execution**: Computations expressed directly using the TensorFlow API run directly. This in effect means that the underlying graph is being executed eagerly as it is being constructed. This is enabled by default. While Eager execution may have some reduced performance in certain cases, it is very beneficial for quick prototyping and debugging.\n",
    "\n",
    "2. **TensorFlow Function**: Graphs can be constructed automatically from Python functions. This is similar to v1, and maintains the performance advantages of having access to the entire graph statically. However, it is a lot cleaner than how v1 operates: the function can be evaluated without the need to use explicit sessions, and the body of the function can use more default python constructs and less of the TensorFlow API, especially for defining dependencies between operations.\n",
    "\n",
    "We begin by importing the regular v2 TensorFlow API, and undoing our previous compatibility changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the kernel and all the changes made previously\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf # has eager execution enabled by default\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution\n",
    "\n",
    "Now, we will begin with something simple. We will create a couple of constants and add them together. Note that the output is immediately available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1.0)\n",
    "print(a) # note that a now has the value exposed\n",
    "\n",
    "b = tf.constant(2.0)\n",
    "c = a + b\n",
    "\n",
    "print(c) # + is executed eagerly\n",
    "print(c.numpy()) # the value as a numpy value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do something more sophisticated. The below example is similar to one we have had before. Notice that because of eager execution, we can choose to encode conditionals and loops either using TensorFlow's API (e.g. using tf.cond) or via their Python constructs.\n",
    "\n",
    "The two options have subtle differences. TensorFlow constructs are managed by TensorFlow, and should be used when the underlying operation is meant to be executed and managed by TensorFlow automatically, e.g. when executing on a cluster with some replication or data-parallelization. While the python constructs execute in the context of the running code, which is not managed by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var:0' shape=() dtype=float32, numpy=5.0>\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0> 0.0\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=5.0> 5.0\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0> 0.0\n",
      "\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=5.0> 5.0 False\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0> 0.0 True\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=5.0> 5.0 False\n"
     ]
    }
   ],
   "source": [
    "t = tf.Variable(5.0, name='var')\n",
    "print(t) # note the value is there, no need to initialize\n",
    "\n",
    "c = tf.constant(4.0)\n",
    "cmp = t > c\n",
    "print(cmp) # comparison is executed eagerly\n",
    "\n",
    "# Perform checks using numpy API\n",
    "print('')\n",
    "for i in range(3):\n",
    "    t = tf.cond(t > c, true_fn=lambda: t.assign(0), false_fn=lambda: t.assign(5))\n",
    "    print(t, t.numpy())\n",
    "\n",
    "# This also works (but not in general)\n",
    "print('')\n",
    "for i in range(3):\n",
    "    cmp = (t > c).numpy()\n",
    "    if cmp:\n",
    "        t = t.assign(0)\n",
    "    else:\n",
    "        t = t.assign(5)\n",
    "    print(t, t.numpy(), cmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sessions and placeholders are now obsolute. There is no need to leave an explicit placeholder for values that will filled at run-time, since graph-construction-time and run-time are now both combined together. Similarly, there is no need to use a session to manage what is run. Instead, the statements are run immediately.\n",
    "\n",
    "### TensorFlow Functions\n",
    "\n",
    "Eager execution simplifies things a lot. But there are still advantages to having static graphs pre-constructed, and then executed on-demand. Primairly for efficiency. Since this allows TensorFlow to apply optimizations to the constructed graph, and find opportunities for parallelization. \n",
    "\n",
    "TensorFlow v2 supports this via TensorFlow functions. A tensorflow function is turned into a graph automatically. A call to the function is similar to running the underlying graph in a session. Parameters to a function are equivalent to placeholders, since they will only be given concrete values at run-time when the function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.def_function.Function object at 0x7fa80052d080>\n",
      "\n",
      "function called\n",
      "tf.Tensor(2, shape=(), dtype=int32) 2\n",
      "function called\n",
      "tf.Tensor(0, shape=(), dtype=int32) 0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test(p):\n",
    "    print('function called')\n",
    "    v = p + 1\n",
    "    if v > 3:\n",
    "        return 0\n",
    "    return v\n",
    "\n",
    "# the function decorator morphes our function and uses it to construct a graph\n",
    "print(test)\n",
    "print('')\n",
    "\n",
    "# test can be called without using sessions\n",
    "r = test(1)\n",
    "print(r, r.numpy())\n",
    "r = test(3)\n",
    "print(r, r.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow transformed test into a TensorFlow function. This function manages when a graph is created from the function. Because of potential dependencies on the size of the input parameters, several calls to the function providing different parameters may result in creating several graphs. TensorFlow guarantees that calls passing inputs of the same type and shape (i.e. dimensionality) will not result in re-creation of graphs.\n",
    "\n",
    "Under the hood, tf.function uses AutoGraph, a new feature in v2 that can transform python entities to graphs automatically.\n",
    "\n",
    "To use proper terminology, using tf.function returns a **Polymorphic Python Function**, which encapsulates graph creation. The polymorphic function manages a cache, everytime this function is called with parameters that have either a new type or new shape, the function produces a concrete graph matching that shape, and stores it in the cache for future use.\n",
    "\n",
    "This concrete graph is represented via a **Concrete Function**. We rarely need to manage or access these constructs ourselfs, since TensorFlow can manage them automatically. TensorFlow provides a way to get the underlying graph from a function, mainly for exporting and storing. We will use this feature to inspect the resulting graph and understand the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'p' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'Greater/y' type=Const>,\n",
       " <tf.Operation 'Greater' type=Greater>,\n",
       " <tf.Operation 'cond' type=StatelessIf>,\n",
       " <tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond/Identity_1' type=Identity>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = test.get_concrete_function(tf.constant(3))\n",
    "cf.graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function gets called when we attempt to concretize it. In fact, the function is passed the parameters we specified. Since Tensor objects (such as tf.constant) are lazy by nature, they can be used to delay execution of the operations inside the function, and instead trace the operations inside the function, and produce the abstract graph.\n",
    "\n",
    "This mechanism is very similar to the bonus part in project 2!\n",
    "\n",
    "\n",
    "### Functions with Side Effects\n",
    "\n",
    "A nice property of v1 sessions is that their effects can survive between runs. This gives the programming model extra richness, since it allows state.\n",
    "\n",
    "This can be achieved with TensorFlow functions as well. Global variables (i.e. variables defined outside the function) survive function execution, and changes to them are reflected to future function calls. Using global variables can give us state.\n",
    "\n",
    "However, implementing such side effects must be done very carefully. TensorFlow functions may be executed in parallel and are generally managed by TensorFlow. The function may run in a different context, may execute operations out of order, and may change certain operations for optimizations.\n",
    "\n",
    "To ensure correctness, side effects must therefore be also managed by TensorFlow. Any modified global variable must be a Tensor itself, such as a TensorFlow variable. Below is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "15\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(0, name='v')\n",
    "\n",
    "@tf.function\n",
    "def func(p):\n",
    "    v.assign_add(p)\n",
    "    return v\n",
    "\n",
    "print(func(5).numpy())\n",
    "print(func(10).numpy())\n",
    "print(func(3).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "\n",
    "To expand on some of the programming abstractions described above:\n",
    "1. Eager execution: [https://www.tensorflow.org/guide/eager](https://www.tensorflow.org/guide/eager).\n",
    "2. TensorFlow Functions: [https://www.tensorflow.org/guide/function](https://www.tensorflow.org/guide/function).\n",
    "3. Distributed Training and parallelization strategies: [https://www.tensorflow.org/guide/distributed_training](https://www.tensorflow.org/guide/distributed_training).\n",
    "\n",
    "For some behind the scenese and design explanations:\n",
    "1. Concrete and polymorphic functions [https://www.tensorflow.org/lite/convert/concrete_function](https://www.tensorflow.org/lite/convert/concrete_function).\n",
    "2. Autograph: [https://www.tensorflow.org/api_docs/python/tf/autograph](https://www.tensorflow.org/api_docs/python/tf/autograph).\n",
    "3. This [Medium Article](https://towardsdatascience.com/tensorflow-control-flow-tf-cond-903e020e722a) on how cond and while_loop work behind the scenes.\n",
    "\n",
    "For complete tutorials into using TensorFlow:\n",
    "1. [10 minutes tutorial](https://cv-tricks.com/artificial-intelligence/deep-learning/deep-learning-frameworks/tensorflow-tutorial/) for TensorFlow V1.\n",
    "2. [Complete Examples](https://github.com/aymericdamien/TensorFlow-Examples/tree/master/tensorflow_v2) of using TensorFlow 2 for machine learning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
